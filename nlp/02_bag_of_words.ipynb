{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow https://www.freecodecamp.org/news/an-introduction-to-bag-of-words-and-how-to-code-it-in-python-for-nlp-282e87a9da04/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('gs://cytora-user-wout/News_Category_Dataset_v2.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Tokenize a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_extraction(sentence):\n",
    "    ignore = list(stopwords_set)    \n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()    \n",
    "    cleaned_text = [w.lower() for w in words if w.lower() not in ignore]    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bird Flu Debate: How to Avoid Ruffling Feathers While Still Having a Real Conversation\n",
      "['bird', 'flu', 'debate', 'avoid', 'ruffling', 'feathers', 'still', 'real', 'conversation']\n",
      "\n",
      "Seth Rogen Says He Smoked Weed In Steven Spielberg's Face\n",
      "['seth', 'rogen', 'says', 'smoked', 'weed', 'steven', 'spielberg', 'face']\n",
      "\n",
      "Clinton Campaign Chairman On Trade Deal: 'Can You Make It Go Away?'\n",
      "['clinton', 'campaign', 'chairman', 'trade', 'deal', 'make', 'go', 'away']\n",
      "\n",
      "People Fed Up With ‘Thoughts And Prayers’ Demand Action After Texas Church Massacre\n",
      "['people', 'fed', 'thoughts', 'prayers', 'demand', 'action', 'texas', 'church', 'massacre']\n",
      "\n",
      "10 Simple Strategies for a Clean and Organized Home\n",
      "['10', 'simple', 'strategies', 'clean', 'organized', 'home']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sen in df['headline'].sample(5):\n",
    "    print(sen)\n",
    "    print(word_extraction(sen))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Words like `isn't` and `U.S.` aren't extracted properly, maybe in case of `isn't` it doesn't matter as it will just get mapped to `isn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Apply tokenization to all sentences\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):    \n",
    "    words = []    \n",
    "    for sentence in sentences:        \n",
    "        w = word_extraction(sentence)        \n",
    "        words.extend(w)            \n",
    "        words = sorted(list(set(words)))    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99884    Dame Helen Mirren Rides The Subway Like The Re...\n",
       "73752    These Two People Could Not Be More Unimpressed...\n",
       "Name: headline, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['could',\n",
       " 'dame',\n",
       " 'hanks',\n",
       " 'helen',\n",
       " 'like',\n",
       " 'mirren',\n",
       " 'people',\n",
       " 'plebeians',\n",
       " 'rapping',\n",
       " 'rest',\n",
       " 'rides',\n",
       " 'subway',\n",
       " 'tom',\n",
       " 'two',\n",
       " 'unimpressed',\n",
       " 'us']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2 = df['headline'].sample(2)\n",
    "display(sample2)\n",
    "tokenize(sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build vocabulary and generate vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bow(allsentences):        \n",
    "    vocab = tokenize(allsentences)\n",
    "    vector_space = pd.DataFrame()\n",
    "    print(f'Done with tokenising vocabular of length: {len(vocab)}')\n",
    "\n",
    "    for sentence in allsentences:\n",
    "        words = word_extraction(sentence)\n",
    "        bag_vector = np.zeros(len(vocab))\n",
    "        for w in words:\n",
    "            for i, word in enumerate(vocab):\n",
    "                if word == w:\n",
    "                    bag_vector[i] += 1\n",
    "            vector_space[sentence] = np.array(bag_vector)\n",
    "#     vector_space = \n",
    "    return vocab, vector_space.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** why is the world `the` still in there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.sample(100) # REMOVE THIS STEP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "now = pd.datetime.now() \n",
    "\n",
    "vocab, vector_space = generate_bow(df['headline'])\n",
    "\n",
    "diff = pd.datetime.now() - now\n",
    "print(f'{diff.seconds / 60:.1f} minutes to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_space.columns = [str(x) for x in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_space.to_csv('data/02_bag_of_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_space[\n",
    "#     (vector_space['04'] == 1) |\n",
    "#     (vector_space['000'] == 1) |\n",
    "#     (vector_space['1'] == 1) |\n",
    "#     (vector_space['102'] == 1) \n",
    "# ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_space = vector_space.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** maybe remove vectors that represent < 6 words, this will be random anyway "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 581 entries, index to young\n",
      "dtypes: float64(580), object(1)\n",
      "memory usage: 454.0+ KB\n"
     ]
    }
   ],
   "source": [
    "vector_space.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['category'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK IF STILL NAMED INDEX\n",
    "\n",
    "Otherwise change name in following cell \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>2012</th>\n",
       "      <th>4</th>\n",
       "      <th>4th</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>workouts</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>would</th>\n",
       "      <th>wow</th>\n",
       "      <th>year</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What You Need To Make a Bangin' Summer Salad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homemade Ricotta Cheese</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carl Bernstein: Donald Trump's Disdain For Fac...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bethenny Frankel's Ex Reportedly Says Daughter...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV Characters In Halloween Costumes: The Super...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               index  000   10   12   15   20  \\\n",
       "0       What You Need To Make a Bangin' Summer Salad  0.0  0.0  0.0  0.0  0.0   \n",
       "1                            Homemade Ricotta Cheese  0.0  0.0  0.0  0.0  0.0   \n",
       "2  Carl Bernstein: Donald Trump's Disdain For Fac...  0.0  0.0  0.0  0.0  0.0   \n",
       "3  Bethenny Frankel's Ex Reportedly Says Daughter...  0.0  0.0  0.0  0.0  0.0   \n",
       "4  TV Characters In Halloween Costumes: The Super...  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   2012    4  4th    5  ...  work  workouts  world  worse  would  wow  year  \\\n",
       "0   0.0  0.0  0.0  0.0  ...   0.0       0.0    0.0    0.0    0.0  0.0   0.0   \n",
       "1   0.0  0.0  0.0  0.0  ...   0.0       0.0    0.0    0.0    0.0  0.0   0.0   \n",
       "2   0.0  0.0  0.0  0.0  ...   0.0       0.0    0.0    1.0    0.0  0.0   0.0   \n",
       "3   0.0  0.0  0.0  0.0  ...   0.0       0.0    0.0    0.0    0.0  0.0   0.0   \n",
       "4   0.0  0.0  0.0  0.0  ...   0.0       0.0    0.0    0.0    0.0  0.0   0.0   \n",
       "\n",
       "   yoga  york  young  \n",
       "0   0.0   0.0    0.0  \n",
       "1   0.0   0.0    0.0  \n",
       "2   0.0   0.0    0.0  \n",
       "3   0.0   0.0    0.0  \n",
       "4   0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 581 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_space.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_space.rename(columns={'index': 'headline'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = vector_space.merge(df[['category', 'headline']], suffixes=('', '_target'), how='inner', on='headline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('data/02_bag_of_words.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
